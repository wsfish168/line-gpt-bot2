import express from 'express';
import dotenv from 'dotenv';
import fs from 'fs';
import { Configuration, OpenAIApi } from 'openai';
import pkg from '@line/bot-sdk';

dotenv.config();

// LINE Bot è¨­å®š
const config = {
  channelAccessToken: process.env.LINE_CHANNEL_ACCESS_TOKEN,
  channelSecret: process.env.LINE_CHANNEL_SECRET
};

const client = new pkg.Client(config);
const app = express();

// è®€å– FAQ
let faqData = [];
try {
  const faqRaw = fs.readFileSync('./faq.json', 'utf8');
  faqData = JSON.parse(faqRaw);
  console.log('âœ… FAQ è¼‰å…¥å®Œæˆï¼Œå…±', faqData.length, 'æ¢');
} catch (err) {
  console.error('âŒ FAQ è¼‰å…¥å¤±æ•—ï¼š', err);
}

// OpenAI è¨­å®š
const openai = new OpenAIApi(
  new Configuration({
    apiKey: process.env.OPENAI_API_KEY
  })
);

// Middleware
app.post('/webhook', pkg.middleware(config), async (req, res) => {
  try {
    const events = req.body.events;
    await Promise.all(events.map(handleEvent));
    res.status(200).end();
  } catch (err) {
    console.error('âŒ Webhook è™•ç†éŒ¯èª¤ï¼š', err);
    res.status(500).end();
  }
});

// è™•ç† LINE è¨Šæ¯
async function handleEvent(event) {
  if (event.type === 'follow') {
    // æ­¡è¿Žè©žï¼ˆå®¢è£½åŒ–ï¼‰
    const profile = await client.getProfile(event.source.userId);
    const welcomeMsg = `å—¨ ${profile.displayName}ï¼Œæ­¡è¿ŽåŠ å…¥ï¼æˆ‘æ˜¯æ‚¨çš„æ™ºèƒ½å®¢æœ ðŸ¤–\nå¯ä»¥å•æˆ‘ç¨…å‹™ã€å…¬å¸è¨­ç«‹ã€è®Šæ›´ç™»è¨˜ç­‰å•é¡Œå–” ðŸ“„`;
    return client.replyMessage(event.replyToken, { type: 'text', text: welcomeMsg });
  }

  if (event.type !== 'message' || event.message.type !== 'text') return;

  const userMsg = event.message.text.trim();

  // FAQ ç¬¬ä¸€å±¤ï¼šå®Œå…¨åŒ¹é…
  for (const faq of faqData) {
    if (faq.keywords.some(keyword => userMsg.includes(keyword))) {
      console.log(`ðŸ“Œ å›žè¦†è·¯å¾‘ï¼šå®Œå…¨åŒ¹é… â†’ ${faq.keywords}`);
      return client.replyMessage(event.replyToken, { type: 'text', text: faq.reply });
    }
  }

  // FAQ ç¬¬äºŒå±¤ï¼šæ¨¡ç³ŠåŒ¹é…ï¼ˆè¨ˆåˆ†ï¼‰
  let bestMatch = null;
  let highestScore = 0;
  for (const faq of faqData) {
    let score = 0;
    faq.keywords.forEach(keyword => {
      if (userMsg.includes(keyword)) score++;
    });
    if (score > highestScore) {
      highestScore = score;
      bestMatch = faq;
    }
  }

  if (bestMatch && highestScore > 0) {
    console.log(`ðŸ“Œ å›žè¦†è·¯å¾‘ï¼šæ¨¡ç³ŠåŒ¹é…ï¼ˆåˆ†æ•¸ ${highestScore}ï¼‰â†’ ${bestMatch.keywords}`);
    return client.replyMessage(event.replyToken, { type: 'text', text: bestMatch.reply });
  }

  // ç¬¬ä¸‰å±¤ï¼šGPT å›žè¦†
  console.log(`ðŸ“Œ å›žè¦†è·¯å¾‘ï¼šGPT å›žè¦†ï¼ˆæœªåŒ¹é… FAQï¼‰`);
  try {
    const completion = await openai.createChatCompletion({
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'system',
          content:
            'ä½ æ˜¯ä½è¦ªåˆ‡çš„ç·šä¸Šå®¢æœï¼Œå…·æœ‰å°ˆæ¥­çš„ç¨…å‹™è«®è©¢èƒ½åŠ›ï¼Œä¹Ÿæ“…é•·è¾¦ç†å…¬å¸è¡Œè™Ÿç›¸é—œçš„è¨­ç«‹ã€è®Šæ›´ç™»è¨˜ï¼Œå›žç­”ç°¡çŸ­æ˜Žç¢ºï¼Œå¯ä»¥ç”¨ä¸€é»žemojiã€‚'
        },
        { role: 'user', content: userMsg }
      ]
    });

    const gptReply = completion.data.choices[0].message.content.trim();
    return client.replyMessage(event.replyToken, { type: 'text', text: gptReply });
  } catch (err) {
    console.error('âŒ GPT å›žè¦†éŒ¯èª¤ï¼š', err);
    return client.replyMessage(event.replyToken, { type: 'text', text: 'æŠ±æ­‰ï¼Œæˆ‘æš«æ™‚ç„¡æ³•å›žç­”æ‚¨çš„å•é¡Œ ðŸ™' });
  }
}

// Render ä¿æ´»ç”¨
app.get('/', (req, res) => {
  res.send('Bot is running');
});

const port = process.env.PORT || 3000;
app.listen(port, () => {
  console.log(`âœ… Server is running on port ${port}`);
});
